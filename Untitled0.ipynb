{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1G2g62y3DXtik0XMPWLcpFaXInFVWQoF2",
      "authorship_tag": "ABX9TyMYXxXfRnhyzgIEeRl/VsEY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/builtbypyro/builtbypyro/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "IpCAtOYaJyIW",
        "outputId": "6c5fef41-73d4-44c3-e8fa-2b4521ed9362"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<audio autoplay=\"\" src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" loop controls>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Step 1 -- press play if you are on phone{ display-mode: \"form\" }\n",
        "%%html\n",
        "<audio autoplay=\"\" src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" loop controls>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "!pip install xgboost\n",
        "!pip install lightgbm\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAHVl-JQKbqo",
        "outputId": "207f2741-3bbf-44e7-c1cd-b06688d0b780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.39)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.15.1 colorlog-6.9.0 optuna-4.2.1\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.14.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile script.py\n",
        "import os\n",
        "os.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\"\n",
        "\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import warnings\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import optuna\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "def normalize_schools(schools):\n",
        "    if isinstance(schools, dict):\n",
        "        return [{\"University\": k, **v} for k, v in schools.items()]\n",
        "    elif isinstance(schools, list):\n",
        "        return schools\n",
        "    return []\n",
        "\n",
        "\n",
        "def safe_extract(data, path, default=np.nan):\n",
        "    current = data\n",
        "    for key in path:\n",
        "        if isinstance(current, dict):\n",
        "            current = current.get(key, default)\n",
        "        else:\n",
        "            return default\n",
        "    return current\n",
        "\n",
        "\n",
        "def extract_features(entry):\n",
        "    features = {}\n",
        "\n",
        "    schools = normalize_schools(entry.get(\"Schools\", []))\n",
        "    features[\"num_applications\"] = len(schools)\n",
        "\n",
        "    demo = entry.get(\"Demographics\", {})\n",
        "    features.update({\n",
        "        \"gender\": str(demo.get(\"Gender\", \"missing\")).lower(),\n",
        "        \"race\": str(demo.get(\"Race/Ethnicity\", \"missing\")).lower(),\n",
        "        \"school_type\": str(demo.get(\"Type of School\", \"missing\")).lower()\n",
        "    })\n",
        "\n",
        "    acad = entry.get(\"Academics\", {})\n",
        "\n",
        "    for test in [\"ACT\", \"SAT\"]:\n",
        "        composite = safe_extract(acad, [test, \"Composite\"]) or acad.get(test)\n",
        "        try:\n",
        "            composite_str = str(composite)\n",
        "            composite_num = re.sub(r\"[^\\d.]\", \"\", composite_str)\n",
        "            features[test.lower()] = float(composite_num) if composite_num else np.nan\n",
        "        except Exception:\n",
        "            features[test.lower()] = np.nan\n",
        "\n",
        "    gpa_data = acad.get(\"UW/W GPA\", {})\n",
        "    if isinstance(gpa_data, dict):\n",
        "        try:\n",
        "            features[\"unweighted_gpa\"] = float(gpa_data.get(\"UW\", np.nan))\n",
        "        except Exception:\n",
        "            features[\"unweighted_gpa\"] = np.nan\n",
        "        try:\n",
        "            features[\"weighted_gpa\"] = float(gpa_data.get(\"W\", np.nan))\n",
        "        except Exception:\n",
        "            features[\"weighted_gpa\"] = np.nan\n",
        "    else:\n",
        "        try:\n",
        "            features[\"weighted_gpa\"] = float(gpa_data) if gpa_data and gpa_data not in [\"N/A\", \"\"] else np.nan\n",
        "            features[\"unweighted_gpa\"] = np.nan\n",
        "        except Exception:\n",
        "            features[\"weighted_gpa\"] = np.nan\n",
        "            features[\"unweighted_gpa\"] = np.nan\n",
        "\n",
        "    coursework = acad.get(\"Coursework\", \"\")\n",
        "    if isinstance(coursework, list):\n",
        "        features[\"coursework\"] = \" \".join(coursework)\n",
        "    else:\n",
        "        features[\"coursework\"] = str(coursework)\n",
        "\n",
        "    ecs = entry.get(\"Extracurriculars\", [])\n",
        "    if not isinstance(ecs, list):\n",
        "        ecs = [str(ecs)] if ecs not in [None, \"N/A\", \"\"] else []\n",
        "    features[\"extracurriculars\"] = \" | \".join([str(e).strip() for e in ecs if e]) or \"none\"\n",
        "    features[\"num_extracurriculars\"] = len(ecs)\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "class BertVectorizer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, model_name='distilbert-base-uncased', max_length=128, batch_size=8):\n",
        "        self.model_name = model_name\n",
        "        self.max_length = max_length\n",
        "        self.batch_size = batch_size\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.cache = {}  # Cache to store already computed embeddings\n",
        "\n",
        "    def _lazy_init(self):\n",
        "        if self.tokenizer is None or self.model is None:\n",
        "            self.tokenizer = DistilBertTokenizer.from_pretrained(self.model_name)\n",
        "            self.model = DistilBertModel.from_pretrained(self.model_name)\n",
        "            self.model.to(self.device)\n",
        "            self.model.eval()\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        self._lazy_init()\n",
        "\n",
        "        if hasattr(X, 'tolist'):\n",
        "            X = X.tolist()\n",
        "        else:\n",
        "            X = list(X)\n",
        "\n",
        "        X = [str(text) for text in X]\n",
        "\n",
        "        # Check cache first; if all texts are cached, return stacked results\n",
        "        new_texts = [text for text in X if text not in self.cache]\n",
        "        cached_embeddings = [self.cache[text] for text in X if text in self.cache]\n",
        "\n",
        "        # If there are texts that are not cached, compute them in batches\n",
        "        if new_texts:\n",
        "            new_embeddings = []\n",
        "            for i in range(0, len(new_texts), self.batch_size):\n",
        "                batch_texts = new_texts[i: i + self.batch_size]\n",
        "                encoded = self.tokenizer(\n",
        "                    batch_texts,\n",
        "                    padding=True,\n",
        "                    truncation=True,\n",
        "                    max_length=self.max_length,\n",
        "                    return_tensors='pt'\n",
        "                )\n",
        "                encoded = {k: v.to(self.device) for k, v in encoded.items()}\n",
        "                with torch.no_grad():\n",
        "                    outputs = self.model(**encoded)\n",
        "                batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "                new_embeddings.append(batch_embeddings)\n",
        "            new_embeddings = np.vstack(new_embeddings)\n",
        "            # Store new embeddings in cache\n",
        "            for text, embedding in zip(new_texts, new_embeddings):\n",
        "                self.cache[text] = embedding\n",
        "        else:\n",
        "            new_embeddings = np.empty((0, self.model.config.hidden_size))\n",
        "\n",
        "        # Reconstruct embeddings in the original order\n",
        "        final_embeddings = []\n",
        "        for text in X:\n",
        "            final_embeddings.append(self.cache[text])\n",
        "        return np.vstack(final_embeddings)\n",
        "\n",
        "\n",
        "def train_model(training_data, n_trials=2):\n",
        "    app_data = []\n",
        "    for entry in training_data:\n",
        "        base_features = extract_features(entry)\n",
        "        schools = normalize_schools(entry.get(\"Schools\", []))\n",
        "        for school in schools:\n",
        "            features = base_features.copy()\n",
        "            features.update({\n",
        "                \"university\": school.get(\"University\", \"unknown\").lower(),\n",
        "                \"application_type\": school.get(\"ED/EA/RD\", \"RD\").lower(),\n",
        "                \"decision\": 1 if \"accepted\" in str(school.get(\"Status\", \"\")).lower() else 0\n",
        "            })\n",
        "            app_data.append(features)\n",
        "\n",
        "    df = pd.DataFrame(app_data)\n",
        "    if df.empty:\n",
        "        raise ValueError(\"No training data available\")\n",
        "\n",
        "    numeric_features = ['act', 'sat', 'weighted_gpa', 'unweighted_gpa', 'num_applications', 'num_extracurriculars']\n",
        "    categorical_features = ['gender', 'race', 'school_type', 'application_type']\n",
        "    text_features_coursework = 'coursework'\n",
        "    text_features_ec = 'extracurriculars'\n",
        "\n",
        "    numeric_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    categorical_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    bert_pipeline_coursework = Pipeline([\n",
        "        ('bert', BertVectorizer(max_length=128, batch_size=8))\n",
        "    ])\n",
        "\n",
        "    bert_pipeline_ec = Pipeline([\n",
        "        ('bert', BertVectorizer(max_length=128, batch_size=8))\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer([\n",
        "        ('num', numeric_pipeline, numeric_features),\n",
        "        ('cat', categorical_pipeline, categorical_features),\n",
        "        ('course', bert_pipeline_coursework, text_features_coursework),\n",
        "        ('ec', bert_pipeline_ec, text_features_ec)\n",
        "    ], remainder='drop')\n",
        "\n",
        "    random_seed = 42\n",
        "    meta_estimator = LogisticRegression(max_iter=1000, random_state=random_seed)\n",
        "\n",
        "    X = df.drop(columns=['decision'])\n",
        "    y = df['decision']\n",
        "\n",
        "    def objective(trial):\n",
        "        xgb_n_estimators = trial.suggest_int('xgb_n_estimators', 100, 300)\n",
        "        xgb_max_depth = trial.suggest_int('xgb_max_depth', 3, 8)\n",
        "        xgb_learning_rate = trial.suggest_float('xgb_learning_rate', 0.01, 0.2, log=True)\n",
        "\n",
        "        lgb_n_estimators = trial.suggest_int('lgb_n_estimators', 100, 300)\n",
        "        lgb_max_depth = trial.suggest_int('lgb_max_depth', 3, 8)\n",
        "        lgb_learning_rate = trial.suggest_float('lgb_learning_rate', 0.01, 0.2, log=True)\n",
        "\n",
        "        xgb_estimator = xgb.XGBClassifier(\n",
        "            use_label_encoder=False,\n",
        "            eval_metric='logloss',\n",
        "            n_estimators=xgb_n_estimators,\n",
        "            max_depth=xgb_max_depth,\n",
        "            learning_rate=xgb_learning_rate,\n",
        "            random_state=random_seed\n",
        "        )\n",
        "        lgb_estimator = lgb.LGBMClassifier(\n",
        "            n_estimators=lgb_n_estimators,\n",
        "            max_depth=lgb_max_depth,\n",
        "            learning_rate=lgb_learning_rate,\n",
        "            random_state=random_seed,\n",
        "            verbose=-1,            # Suppress warnings\n",
        "            min_split_gain=0.1       # Increase minimum gain to reduce unnecessary splits\n",
        "        )\n",
        "        base_estimators = [\n",
        "            ('xgb', xgb_estimator),\n",
        "            ('lgb', lgb_estimator)\n",
        "        ]\n",
        "\n",
        "        stacking_model = StackingClassifier(\n",
        "            estimators=base_estimators,\n",
        "            final_estimator=meta_estimator,\n",
        "            cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=random_seed),\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('classifier', stacking_model)\n",
        "        ])\n",
        "\n",
        "        cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
        "        scores = cross_val_score(pipeline, X, y, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
        "        mean_score = np.mean(scores)\n",
        "        trial.set_user_attr(\"mean_cv_score\", mean_score)\n",
        "        return mean_score\n",
        "\n",
        "    print(\"Starting hyperparameter optimization using Optuna...\")\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=n_trials, n_jobs=1)\n",
        "\n",
        "    print(\"Best trial:\")\n",
        "    print(\"  Value (mean CV ROC AUC):\", study.best_trial.value)\n",
        "    print(\"  Params:\", study.best_trial.params)\n",
        "\n",
        "    best_params = study.best_trial.params\n",
        "\n",
        "    best_xgb = xgb.XGBClassifier(\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss',\n",
        "        n_estimators=best_params['xgb_n_estimators'],\n",
        "        max_depth=best_params['xgb_max_depth'],\n",
        "        learning_rate=best_params['xgb_learning_rate'],\n",
        "        random_state=random_seed\n",
        "    )\n",
        "    best_lgb = lgb.LGBMClassifier(\n",
        "        n_estimators=best_params['lgb_n_estimators'],\n",
        "        max_depth=best_params['lgb_max_depth'],\n",
        "        learning_rate=best_params['lgb_learning_rate'],\n",
        "        random_state=random_seed,\n",
        "        verbose=-1,\n",
        "        min_split_gain=0.1\n",
        "    )\n",
        "    base_estimators = [\n",
        "        ('xgb', best_xgb),\n",
        "        ('lgb', best_lgb)\n",
        "    ]\n",
        "\n",
        "    best_stacking = StackingClassifier(\n",
        "        estimators=base_estimators,\n",
        "        final_estimator=meta_estimator,\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed),\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    best_pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', best_stacking)\n",
        "    ])\n",
        "\n",
        "    print(\"Training the final model on the full dataset...\")\n",
        "    best_pipeline.fit(X, y)\n",
        "\n",
        "    joblib.dump(best_pipeline, 'admission_model_advanced.pkl')\n",
        "    print(\"Advanced model trained and saved as 'admission_model_advanced.pkl'\")\n",
        "\n",
        "    return best_pipeline, study\n",
        "\n",
        "\n",
        "def predict_new_application(new_app_file):\n",
        "    try:\n",
        "        model = joblib.load('admission_model_advanced.pkl')\n",
        "    except FileNotFoundError:\n",
        "        raise RuntimeError(\"Advanced model not found. Please train the model first with training data.\")\n",
        "\n",
        "    with open(new_app_file) as f:\n",
        "        new_data = json.load(f)\n",
        "\n",
        "    results = {}\n",
        "    base_features = extract_features(new_data)\n",
        "    schools = normalize_schools(new_data.get(\"Schools\", []))\n",
        "\n",
        "    for school in schools:\n",
        "        try:\n",
        "            features = base_features.copy()\n",
        "            features.update({\n",
        "                \"university\": school.get(\"University\", \"unknown\").lower(),\n",
        "                \"application_type\": school.get(\"ED/EA/RD\", \"RD\").lower()\n",
        "            })\n",
        "            df_new = pd.DataFrame([features])\n",
        "            proba = model.predict_proba(df_new)[0][1]\n",
        "            recommendation = (\n",
        "                'Safety' if proba >= 0.7\n",
        "                else 'Reach' if proba <= 0.3\n",
        "                else 'Target'\n",
        "            )\n",
        "            results[school[\"University\"]] = {\n",
        "                'probability': round(proba, 3),\n",
        "                'recommendation': recommendation\n",
        "            }\n",
        "        except Exception as e:\n",
        "            results[school[\"University\"]] = {'error': str(e)}\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import sys\n",
        "    if len(sys.argv) == 1:\n",
        "        print(\"Training advanced model with provided data...\")\n",
        "        if not os.path.exists(\"applications.json\"):\n",
        "            raise FileNotFoundError(\"Training data file 'applications.json' not found.\")\n",
        "        with open(\"applications.json\") as f:\n",
        "            training_data = json.load(f)\n",
        "        final_model, study = train_model(training_data, n_trials=3)\n",
        "    elif len(sys.argv) == 2:\n",
        "        new_app_file = sys.argv[1]\n",
        "        print(f\"Making predictions for {new_app_file}...\")\n",
        "        results = predict_new_application(new_app_file)\n",
        "        print(\"\\nPredictions:\")\n",
        "        for school, pred in results.items():\n",
        "            print(f\"{school}: {pred}\")\n",
        "    else:\n",
        "        print(\"Usage:\")\n",
        "        print(\"  Training: python script.py\")\n",
        "        print(\"  Prediction: python script.py new_application.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXDM4EfFKGxe",
        "outputId": "5fdf5e44-d532-4eee-e6ae-8d85e4f129db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python script.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ReTiAiXK1j7",
        "outputId": "5b796a61-4846-49d4-971f-bc7f637a50e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-19 21:54:27.107124: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742421267.127250    1307 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742421267.133378    1307 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-19 21:54:27.154302: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Training advanced model with provided data...\n",
            "Starting hyperparameter optimization using Optuna...\n",
            "\u001b[32m[I 2025-03-19 21:54:30,259]\u001b[0m A new study created in memory with name: no-name-331be2e5-74c9-4e62-ab07-90d925c9c764\u001b[0m\n",
            "2025-03-19 21:54:39.128029: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-03-19 21:54:39.148085: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742421279.162424    1357 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742421279.173009    1357 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742421279.181918    1358 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742421279.192134    1358 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 392kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 41.3MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 2.14MB/s]\n",
            "config.json: 100% 483/483 [00:00<00:00, 3.77MB/s]\n",
            "model.safetensors: 100% 268M/268M [00:01<00:00, 218MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[21:57:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "[21:57:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[21:59:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:00:16] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:02:28] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "[22:02:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "[22:03:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "[22:04:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:06:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:08:16] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:09:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "[22:10:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2025-03-19 22:11:10,815]\u001b[0m Trial 0 finished with value: 0.9939583993904839 and parameters: {'xgb_n_estimators': 249, 'xgb_max_depth': 4, 'xgb_learning_rate': 0.14299954181708477, 'lgb_n_estimators': 186, 'lgb_max_depth': 4, 'lgb_learning_rate': 0.04150783490242189}. Best is trial 0 with value: 0.9939583993904839.\u001b[0m\n",
            "2025-03-19 22:11:19.812874: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742422279.846749    5469 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742422279.857178    5469 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-19 22:11:22.292628: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742422282.325970    5480 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742422282.336256    5480 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:14:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "[22:14:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:15:53] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "[22:15:55] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:17:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "[22:17:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:18:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "[22:18:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:21:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:21:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:22:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:23:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2025-03-19 22:23:57,725]\u001b[0m Trial 1 finished with value: 0.9937851779782925 and parameters: {'xgb_n_estimators': 120, 'xgb_max_depth': 6, 'xgb_learning_rate': 0.04494386630690403, 'lgb_n_estimators': 130, 'lgb_max_depth': 7, 'lgb_learning_rate': 0.02068368775843369}. Best is trial 0 with value: 0.9939583993904839.\u001b[0m\n",
            "2025-03-19 22:24:08.942563: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742423048.979454    8649 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742423048.989512    8649 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:26:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:27:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:29:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:29:21] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:31:21] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "[22:31:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "[22:32:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "[22:32:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "2025-03-19 22:34:06.180011: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742423646.212901   11098 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742423646.222939   11098 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:35:54] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:37:18] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:38:31] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "[22:39:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "\u001b[32m[I 2025-03-19 22:40:14,465]\u001b[0m Trial 2 finished with value: 0.9937715609432664 and parameters: {'xgb_n_estimators': 263, 'xgb_max_depth': 3, 'xgb_learning_rate': 0.039800001390163466, 'lgb_n_estimators': 125, 'lgb_max_depth': 7, 'lgb_learning_rate': 0.019953912845673043}. Best is trial 0 with value: 0.9939583993904839.\u001b[0m\n",
            "Best trial:\n",
            "  Value (mean CV ROC AUC): 0.9939583993904839\n",
            "  Params: {'xgb_n_estimators': 249, 'xgb_max_depth': 4, 'xgb_learning_rate': 0.14299954181708477, 'lgb_n_estimators': 186, 'lgb_max_depth': 4, 'lgb_learning_rate': 0.04150783490242189}\n",
            "Training the final model on the full dataset...\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:42:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:44:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "[22:44:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[22:48:14] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "[22:48:14] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "[22:50:18] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "Advanced model trained and saved as 'admission_model_advanced.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python"
      ],
      "metadata": {
        "id": "gq-BNzIGscFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile new_application.json\n",
        "\n",
        "{\n",
        "  \"Schools\": [\n",
        "    {\n",
        "      \"University\": \"Harvard University\",\n",
        "      \"ED/EA/RD\": \"RD\"\n",
        "    },\n",
        "    {\n",
        "      \"University\": \"Stanford University\",\n",
        "      \"ED/EA/RD\": \"RD\"\n",
        "    }\n",
        "  ],\n",
        "  \"Demographics\": {\n",
        "    \"Gender\": \"Female\",\n",
        "    \"Race/Ethnicity\": \"Asian\",\n",
        "    \"Type of School\": \"Public\"\n",
        "  },\n",
        "  \"Academics\": {\n",
        "    \"ACT\": {\n",
        "      \"Composite\": \"34\"\n",
        "    },\n",
        "    \"SAT\": {\n",
        "      \"Composite\": \"1520\"\n",
        "    },\n",
        "    \"UW/W GPA\": {\n",
        "      \"UW\": \"3.95\",\n",
        "      \"W\": \"4.5\"\n",
        "    },\n",
        "    \"Coursework\": [\n",
        "      \"AP Calculus BC\",\n",
        "      \"AP Physics C\",\n",
        "      \"AP English Literature\",\n",
        "      \"AP U.S. History\",\n",
        "      \"AP Computer Science A\"\n",
        "    ]\n",
        "  },\n",
        "  \"Extracurriculars\": [\n",
        "    \"President of Science Club\",\n",
        "    \"Varsity Tennis Team Captain\",\n",
        "    \"Volunteer at Local Hospital\",\n",
        "    \"Piano - State Level Competitions\",\n",
        "    \"Internship at Tech Startup\"\n",
        "  ]\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mvrxIiUtJmL",
        "outputId": "76284a63-c2fe-4795-8069-7277a326dbdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing new_application.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python script.py new_application.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK--CbF3tNG3",
        "outputId": "b917d4a0-7e79-4db0-83c6-40b04b95e76b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-19 23:20:14.511478: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742426414.531473   22356 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742426414.537601   22356 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-19 23:20:14.557767: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Making predictions for new_application.json...\n",
            "\n",
            "Predictions:\n",
            "Harvard University: {'probability': np.float64(0.209), 'recommendation': 'Reach'}\n",
            "Stanford University: {'probability': np.float64(0.209), 'recommendation': 'Reach'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrq7sKEftnls",
        "outputId": "a2652c11-596f-456a-887e-766e164f05f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oie4XsLRtUkI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}